{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPYUK7bP669H7ZcTJAiY1a4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"uq6U-B1FAQ90","executionInfo":{"status":"ok","timestamp":1722884081445,"user_tz":-210,"elapsed":4,"user":{"displayName":"ayeh","userId":"03147515127751446265"}}},"outputs":[],"source":["import numpy as np\n","\n","class LogisticRegression:\n","    def __init__(self, learning_rate=0.0001, num_iter=10000, intercept=True):\n","        self.learning_rate = learning_rate\n","        self.num_iter = num_iter\n","        self.intercept = intercept\n","\n","    def add_intercept(self, X):\n","        intercept = np.ones((X.shape[0], 1))\n","        return np.concatenate((intercept, X), axis=1)\n","\n","    def loglikelihood(self, h, y):\n","        return -(y*np.log(h) + (1-y)*np.log(1-h)).mean()\n","\n","    def sigmoid(self, z):\n","        return 1 / (1 + np.exp(-z))\n","\n","    def learn(self, X, y):\n","        if self.intercept:\n","            X = self.add_intercept(X)\n","\n","        self.theta = np.zeros(X.shape[1])\n","\n","        for i in range(self.num_iter):\n","            z = np.dot(X, self.theta)\n","            h = self.sigmoid(z)\n","            gradient = np.dot(X.T,(y - h))\n","            self.theta += self.learning_rate * gradient\n","\n","            if(i % 10000 == 0):\n","                z = np.dot(X, self.theta)\n","                h = self.sigmoid(z)\n","                loss = self.loglikelihood(h,y)\n","                print(f'max of likelihood function: {loss} \\t')\n","\n","        return(self.theta)\n","\n","    def predict_probability(self, X):\n","        if self.intercept:\n","            X = self.add_intercept(X)\n","\n","        return self.sigmoid(np.dot(X, self.theta))\n","\n","    def predict(self, X):\n","        return ((self.predict_probability(X) >= 0.5) * 1)\n"]}]}